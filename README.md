# CS229 From Scratch

## 🎯 Objective
Re-implement the core algorithms and concepts from the **CS229 (Stanford, Andrew Ng & Tengyu Ma)** course entirely from scratch, **without using machine learning libraries like `scikit-learn` or `TensorFlow`**.

The goal is to gain a **deep mathematical and algorithmic understanding** of each method by building them step by step, only with fundamental Python libraries.

---

## 📖 Project Description
This repository contains Python implementations of fundamental machine learning models and concepts, following the CS229 curriculum:

- **Linear Regression:** Closed-form solution and gradient descent
- **Logistic Regression:** Maximum likelihood estimation and gradient descent
- *(to come)* Support Vector Machines (SVM): Hinge loss and kernel intuition
- *(to come)* Principal Component Analysis (PCA): Eigen decomposition / SVD
- *(to come)* Simple Neural Networks: One hidden layer with backpropagation

Each implementation is written **from scratch** and includes:
- Clear, reusable Python functions with detailed documentation
- Small synthetic datasets for testing
- Visualizations and experiments with `matplotlib`
- Step-by-step notebooks to illustrate the mathematics and logic

---

## 🛠 Tools Used
Only **standard scientific Python libraries** are used:
- `numpy` → numerical computations
- `pandas` → dataset handling
- `matplotlib` → visualization

⚠️ **No high-level ML libraries** (like `scikit-learn`, `keras`, `pytorch`, etc.) are used, in order to really focus on the **core algorithms**.

---

## 🚀 Current Progress
📌 Currently working on: **Regression models** (linear and logistic).  
Upcoming: classification margins, SVMs, PCA, and neural networks.

---

## 🧠 Skills Developed
- Applying **mathematics to machine learning** (optimization, linear algebra, probability)
- Writing **clean and well-structured code** with NumPy
- Creating **ML algorithms from first principles**
- Building a foundation to better understand how libraries like scikit-learn are implemented  


